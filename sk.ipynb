{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ai video to image skeleton  stick figure\n",
        "\n",
        "!pip install mediapipe opencv-python\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Load your video\n",
        "cap = cv2.VideoCapture('/sk demo.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  # Convert the frame to RGB\n",
        "  image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Process the frame with MediaPipe Pose\n",
        "  results = pose.process(image_rgb)\n",
        "\n",
        "  # Draw the skeleton if pose landmarks are detected\n",
        "  if results.pose_landmarks:\n",
        "    mp_drawing.draw_landmarks(\n",
        "      frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "      mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
        "      mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
        "    )\n",
        "\n",
        "  # Display the frame\n",
        "  from google.colab.patches import cv2_imshow #This line was not indented correctly.\n",
        "\n",
        "  cv2_imshow(frame)\n",
        "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "X8GrdddAfD98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert skeletor avtar\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow #This line was not indented correctly.\n",
        "# ai video to image skeleton  stick figure\n",
        "\n",
        "!pip install mediapipe opencv-python\n",
        "\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Load your video\n",
        "cap = cv2.VideoCapture('/sk demo.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  # Convert the frame to RGB\n",
        "  image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Process the frame with MediaPipe Pose\n",
        "  results = pose.process(image_rgb)\n",
        "\n",
        "  # Create a black image for the avatar\n",
        "  avatar = np.zeros_like(frame)\n",
        "\n",
        "  # Draw the skeleton if pose landmarks are detected\n",
        "  if results.pose_landmarks:\n",
        "    mp_drawing.draw_landmarks(\n",
        "      avatar, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "      mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
        "      mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
        "    )\n",
        "\n",
        "  # Display the avatar\n",
        "  cv2_imshow(avatar)\n",
        "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "bndzd-h-fEBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert skelator single video currently multyple view\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "# ai video to image skeleton stick figure\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Load your video\n",
        "cap = cv2.VideoCapture('/sk demo.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  # Convert the frame to RGB\n",
        "  image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Process the frame with MediaPipe Pose\n",
        "  results = pose.process(image_rgb)\n",
        "\n",
        "  # Create a black image for the avatar\n",
        "  avatar = np.zeros_like(frame)\n",
        "\n",
        "  # Draw the skeleton if pose landmarks are detected\n",
        "  if results.pose_landmarks:\n",
        "    mp_drawing.draw_landmarks(\n",
        "      avatar, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "      mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
        "      mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
        "    )\n",
        "\n",
        "  # Display the avatar\n",
        "  cv2_imshow(avatar)\n",
        "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "CiiI85COfEFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUf1voy6fEIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHitjlRQfEMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FYPXTEyTfEPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2BqcMNbfESk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNiyWRLDfEVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}